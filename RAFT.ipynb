{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RAFT.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMW8+XLyhR2mg8YtIa6xK/r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeremy26/video_analysis_course/blob/main/RAFT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVdTJsytfFL9"
      },
      "source": [
        "# RAFT\n",
        "\n",
        "Let's run a RAFT optical flow algorithm\n",
        "<p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czK46V1BZH4K"
      },
      "source": [
        "!git clone https://github.com/princeton-vl/RAFT.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLVN_ODAZV5t"
      },
      "source": [
        "!ls RAFT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEWfWfLG6lFF"
      },
      "source": [
        "!./RAFT/download_models.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBqcqasaeBzn"
      },
      "source": [
        "!wget https://thinkautonomous-raft.s3.eu-west-3.amazonaws.com/raft_data.zip && unzip raft_data.zip && rm raft_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6K1hZE62nGo"
      },
      "source": [
        "!python3 raft_run.py --model models/raft-sintel.pth --video crowd-3.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko7r_YcM30aB"
      },
      "source": [
        "!python3 raft_run.py --model models/raft-kitti.pth --video kitti_3.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RWo_aivW0Tn"
      },
      "source": [
        "# Run RAFT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2P4eAMEUHrY"
      },
      "source": [
        "import sys\n",
        "sys.path.append('RAFT/core')\n",
        "from raft import RAFT\n",
        "from utils import flow_viz\n",
        "from utils.utils import InputPadder\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from utils import flow_viz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaMWXY9gXxHe"
      },
      "source": [
        "def frame_preprocess(frame, device):\n",
        "    frame = torch.from_numpy(frame).permute(2, 0, 1).float()\n",
        "    frame = frame.unsqueeze(0)\n",
        "    frame = frame.to(device)\n",
        "    return frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5xB7cdVX7gW"
      },
      "source": [
        "def get_cpu_model(model):\n",
        "    new_model = OrderedDict()\n",
        "    # get all layer's names from model\n",
        "    for name in model:\n",
        "        # create new name and update new model\n",
        "        new_name = name[7:]\n",
        "        new_model[new_name] = model[name]\n",
        "    return new_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69LX9JdkFPJh"
      },
      "source": [
        "def inference():\n",
        "    # Outputs to return\n",
        "    result_flows_vectors = []\n",
        "    result_flows_images = []\n",
        "    images = []\n",
        "\n",
        "    # Get the RAFT model\n",
        "    model = RAFT()\n",
        "\n",
        "    # Load pretrained weights\n",
        "    pretrained_weights = torch.load(\"models/raft-kitti.pth\", map_location=torch.device(\"cpu\"))\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda\"\n",
        "        # parallel between available GPUs\n",
        "        model = torch.nn.DataParallel(model)\n",
        "        # load the pretrained weights into model\n",
        "        model.load_state_dict(pretrained_weights)\n",
        "        model.to(device)\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "        # change key names for CPU runtime\n",
        "        pretrained_weights = get_cpu_model(pretrained_weights)\n",
        "        # load the pretrained weights into model\n",
        "        model.load_state_dict(pretrained_weights)\n",
        "\n",
        "    # change model's mode to evaluation\n",
        "    model.eval()\n",
        "\n",
        "    video_path = \"kitti_3.mp4\"\n",
        "\n",
        "    # capture the video and get the first frame\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    ret, frame_1 = cap.read()\n",
        "\n",
        "    # Save the image\n",
        "    images.append(cv2.cvtColor(frame_1, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # frame preprocessing\n",
        "    frame_1 = frame_preprocess(frame_1, device)\n",
        "\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        while True:\n",
        "            # read the next frame\n",
        "            ret, frame_2_b = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            # save the image\n",
        "            images.append(cv2.cvtColor(frame_2_b, cv2.COLOR_BGR2RGB))\n",
        "            # preprocessing\n",
        "            frame_2_b = frame_preprocess(frame_2_b, device)\n",
        "            padder = InputPadder(frame_1.shape, mode=\"kitti\")\n",
        "            frame_1, frame_2 = padder.pad(frame_1, frame_2_b)\n",
        "            # predict the flow\n",
        "            flow_low, flow_up = model(frame_1, frame_2, iters=12, test_mode=True)\n",
        "            # save the flow\n",
        "            result_flows_vectors.append(flow_up.cpu().detach().numpy())\n",
        "            # transform to image\n",
        "            flo = flow_up[0].permute(1,2,0).cpu().numpy()\n",
        "            flo = flow_viz.flow_to_image(flo)\n",
        "            # save the image\n",
        "            result_flows_images.append(flo)\n",
        "            # mode forward one frame\n",
        "            frame_1 = frame_2_b    \n",
        "    return result_flows_vectors, result_flows_images, images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkTqOanXVhHN"
      },
      "source": [
        "fl_vectors, fl_images, images = inference()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1zr2PwIXiRs"
      },
      "source": [
        "# Understand the Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoOMw2ynUAo-"
      },
      "source": [
        "print(len(fl_images))\n",
        "print(len(fl_vectors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA4adCy_atTh"
      },
      "source": [
        "print(fl_vectors[0].shape)\n",
        "print(fl_images[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgzBB8sSdty7"
      },
      "source": [
        "f, (ax0, ax1)= plt.subplots(1, 2, figsize=(20,10))\n",
        "ax0.imshow(images[0])\n",
        "ax1.imshow(fl_images[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sPvie43a0HR"
      },
      "source": [
        "# Run an Object Detection algorithm to identify individual objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_Y_zDwd86x2"
      },
      "source": [
        "!python3 -m pip install yolov4==2.0.2 # After Checking, YOLO 2.0.2 works without modifying anything. Otherwise keep 1.2.1\n",
        "from yolov4.tf import YOLOv4\n",
        "import tensorflow as tf\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YjkA7M7fGYX"
      },
      "source": [
        "yolo = YOLOv4(tiny=True)\n",
        "yolo.classes = \"coco.names\"\n",
        "yolo.make_model()\n",
        "yolo.load_weights(\"yolov4-tiny.weights\", weights_type=\"yolo\")\n",
        "\n",
        "def run_obstacle_detection(img):\n",
        "    start_time=time.time()\n",
        "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    resized_image = yolo.resize_image(img)\n",
        "    # 0 ~ 255 to 0.0 ~ 1.0\n",
        "    resized_image = resized_image / 255.\n",
        "    #input_data == Dim(1, input_size, input_size, channels)\n",
        "    input_data = resized_image[np.newaxis, ...].astype(np.float32)\n",
        "\n",
        "    candidates = yolo.model.predict(input_data)\n",
        "\n",
        "    _candidates = []\n",
        "    result = img.copy()\n",
        "    for candidate in candidates:\n",
        "        batch_size = candidate.shape[0]\n",
        "        grid_size = candidate.shape[1]\n",
        "        _candidates.append(tf.reshape(candidate, shape=(1, grid_size * grid_size * 3, -1)))\n",
        "        #candidates == Dim(batch, candidates, (bbox))\n",
        "        candidates = np.concatenate(_candidates, axis=1)\n",
        "        #pred_bboxes == Dim(candidates, (x, y, w, h, class_id, prob))\n",
        "        pred_bboxes = yolo.candidates_to_pred_bboxes(candidates[0], iou_threshold=0.35, score_threshold=0.40)\n",
        "        pred_bboxes = pred_bboxes[~(pred_bboxes==0).all(1)] #https://stackoverflow.com/questions/35673095/python-how-to-eliminate-all-the-zero-rows-from-a-matrix-in-numpy?lq=1\n",
        "        pred_bboxes = yolo.fit_pred_bboxes_to_original(pred_bboxes, img.shape)\n",
        "        exec_time = time.time() - start_time\n",
        "        #print(\"time: {:.2f} ms\".format(exec_time * 1000))\n",
        "        result = yolo.draw_bboxes(img, pred_bboxes)\n",
        "    return result, pred_bboxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM0OEQp1IusZ"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_yolo = images[0]\n",
        "\n",
        "result, pred_bboxes = run_obstacle_detection(image_yolo)\n",
        "\n",
        "plt.imshow(result)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySQ0uDjSARqs"
      },
      "source": [
        "print(fl_vectors[0].shape)\n",
        "print(fl_vectors[0][0][0])\n",
        "print(fl_vectors[0][0][0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8UmtZSG9Tyz"
      },
      "source": [
        "def add_arrow_to_box(result, pred_bboxes, fl_vectors):\n",
        "    h, w, _ = result.shape\n",
        "\n",
        "    for box in pred_bboxes:\n",
        "        center_x = int(box[0]*w)\n",
        "        center_y = int(box[1]*h)\n",
        "        width_box_2 = int(box[2]*w/2)\n",
        "        height_box_2 = int(box[3]*h/2)\n",
        "\n",
        "        box_x1 = int(center_x - width_box_2)\n",
        "        box_y1 = int(center_y - height_box_2)\n",
        "        box_x2 = int(center_x + width_box_2)\n",
        "        box_y2 = int(center_y + height_box_2)\n",
        "\n",
        "        flows_u = fl_vectors[0][0][box_y1:box_y2,box_x1:box_x2]\n",
        "        mean_u = flows_u.mean()\n",
        "        flows_v = fl_vectors[0][1][box_y1:box_y2,box_x1:box_x2]\n",
        "        mean_v  =flows_v.mean()\n",
        "        image_arr = cv2.arrowedLine(result, (center_x,center_y), (center_x + int(mean_u)*2,center_y+int(mean_v)*2), (255,0,0), 13)\n",
        "    return image_arr\n",
        "\n",
        "image_arr = add_arrow_to_box(result, pred_bboxes, fl_vectors[0])\n",
        "plt.imshow(image_arr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO5nN4zAbTFL"
      },
      "source": [
        "# Run it on the full Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_GOfA-5WfV1"
      },
      "source": [
        "final_vid = []\n",
        "\n",
        "for idx, img in enumerate(images):\n",
        "    # Run an Object Detection Algorithm\n",
        "    result, pred_bboxes = run_obstacle_detection(img)\n",
        "\n",
        "    if len(pred_bboxes)>0:\n",
        "        #If we have boxes, get the Optical Flow we ran before\n",
        "        fl_vec = fl_vectors[idx]\n",
        "        fl_img = fl_images[idx]\n",
        "        fl_out = add_arrow_to_box(result, pred_bboxes, fl_vec)\n",
        "        img_final = np.concatenate([fl_out, fl_img], axis=0)\n",
        "    final_vid.append(img_final)\n",
        "\n",
        "out = cv2.VideoWriter(\"output.mp4\",cv2.VideoWriter_fourcc(*'mp4v'), 15.0, (out_flo.shape[1] ,out_flo.shape[0]))\n",
        "for i in range(len(final_vid)):\n",
        "    out.write(final_vid[i].astype(np.uint8))\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MXSyERvc2xx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}